name: Web Scraping

on:
  push:
    branches:
      - main

jobs:
  scrape_and_write:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.x
    - name: Install Chrome browser
      run: |
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo dpkg -i google-chrome-stable_current_amd64.deb
        sudo apt-get -f install -y

    - name: Install Chrome WebDriver
      run: |
        LATEST=$(wget -q -O - https://chromedriver.storage.googleapis.com/LATEST_RELEASE)
        wget https://chromedriver.storage.googleapis.com/$LATEST/chromedriver_linux64.zip
        unzip chromedriver_linux64.zip
        sudo mv chromedriver /usr/local/bin/chromedriver
        sudo chmod +x /usr/local/bin/chromedriver
    - name: Install dependencies
      run: pip install beautifulsoup4 requests selenium

    - name: Run web scraper
      run: python ./get_clash.py

    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add clash.txt
        git commit -m "Update scraped data"
        git push
